// ============================================
// AGI PROJECT III - LEVEL 2: COMPLETE MoE
// Router + 3 Experts working end-to-end
// ============================================

print("â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—\n")
print("â•‘         AGI PROJECT III - LEVEL 2: COMPLETE MoE             â•‘\n")
print("â•‘         Router + 3 Specialized Experts                      â•‘\n")
print("â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n\n")

// ============================================
// PHASE 1: TRAIN EXPERT MATH
// ============================================

print("â•â•â• PHASE 1: EXPERT MATH â•â•â•\n")
print("Task: Additions (a + b)\n")
print("Dataset: 10 examples (0+0 to 2+2)\n\n")

let X_math = tensor([
    0.0, 0.0,
    1.0, 0.0,
    0.0, 1.0,
    1.0, 1.0,
    2.0, 0.0,
    2.0, 1.0,
    1.0, 2.0,
    2.0, 2.0,
    0.0, 2.0,
    0.0, 0.0
], [10, 2])

let Y_math = tensor([
    1.0, 0.0, 0.0, 0.0, 0.0,  // 0+0=0
    0.0, 1.0, 0.0, 0.0, 0.0,  // 1+0=1
    0.0, 1.0, 0.0, 0.0, 0.0,  // 0+1=1
    0.0, 0.0, 1.0, 0.0, 0.0,  // 1+1=2
    0.0, 0.0, 1.0, 0.0, 0.0,  // 2+0=2
    0.0, 0.0, 0.0, 1.0, 0.0,  // 2+1=3
    0.0, 0.0, 0.0, 1.0, 0.0,  // 1+2=3
    0.0, 0.0, 0.0, 0.0, 1.0,  // 2+2=4
    0.0, 0.0, 1.0, 0.0, 0.0,  // 0+2=2
    1.0, 0.0, 0.0, 0.0, 0.0   // 0+0=0
], [10, 5])

// Expert Math: 2 â†’ 16 â†’ 5
let W1_math = tensor_randn_seeded([2, 16], 42)
W1_math = tensor_requires_grad(W1_math, true)
let b1_math = tensor_zeros([16])
b1_math = tensor_requires_grad(b1_math, true)

let W2_math = tensor_randn_seeded([16, 5], 123)
W2_math = tensor_requires_grad(W2_math, true)
let b2_math = tensor_zeros([5])
b2_math = tensor_requires_grad(b2_math, true)

print("Training Expert Math (2000 epochs)...\n")

let lr = 0.01
let optimizer_math = sgd_create(lr)
let epoch = 0

while epoch < 2000 {
    let h1 = nn_linear(X_math, W1_math, b1_math)
    h1 = nn_relu(h1)
    let logits = nn_linear(h1, W2_math, b2_math)
    let loss = nn_cross_entropy_logits(logits, Y_math)

    tensor_backward(loss)

    let params = [W1_math, b1_math, W2_math, b2_math]
    let updated = sgd_step(optimizer_math, params)

    W1_math = updated[0]
    b1_math = updated[1]
    W2_math = updated[2]
    b2_math = updated[3]

    epoch = epoch + 1
}

print("âœ… Expert Math trained\n\n")

// ============================================
// PHASE 2: TRAIN EXPERT LOGIC
// ============================================

print("â•â•â• PHASE 2: EXPERT LOGIC â•â•â•\n")
print("Task: Comparison (a > b?)\n")
print("Dataset: 10 examples\n\n")

let X_logic = tensor([
    0.0, 1.0,  // 0>1? no (0)
    1.0, 0.0,  // 1>0? yes (1)
    0.0, 0.0,  // 0>0? no (0)
    2.0, 1.0,  // 2>1? yes (1)
    1.0, 2.0,  // 1>2? no (0)
    2.0, 0.0,  // 2>0? yes (1)
    0.0, 2.0,  // 0>2? no (0)
    1.0, 1.0,  // 1>1? no (0)
    2.0, 2.0,  // 2>2? no (0)
    1.0, 0.0   // 1>0? yes (1)
], [10, 2])

let Y_logic = tensor([
    1.0, 0.0,  // no
    0.0, 1.0,  // yes
    1.0, 0.0,  // no
    0.0, 1.0,  // yes
    1.0, 0.0,  // no
    0.0, 1.0,  // yes
    1.0, 0.0,  // no
    1.0, 0.0,  // no
    1.0, 0.0,  // no
    0.0, 1.0   // yes
], [10, 2])

// Expert Logic: 2 â†’ 8 â†’ 2
let W1_logic = tensor_randn_seeded([2, 8], 55)
W1_logic = tensor_requires_grad(W1_logic, true)
let b1_logic = tensor_zeros([8])
b1_logic = tensor_requires_grad(b1_logic, true)

let W2_logic = tensor_randn_seeded([8, 2], 66)
W2_logic = tensor_requires_grad(W2_logic, true)
let b2_logic = tensor_zeros([2])
b2_logic = tensor_requires_grad(b2_logic, true)

print("Training Expert Logic (2000 epochs)...\n")

let optimizer_logic = sgd_create(lr)
epoch = 0

while epoch < 2000 {
    let h1 = nn_linear(X_logic, W1_logic, b1_logic)
    h1 = nn_relu(h1)
    let logits = nn_linear(h1, W2_logic, b2_logic)
    let loss = nn_cross_entropy_logits(logits, Y_logic)

    tensor_backward(loss)

    let params = [W1_logic, b1_logic, W2_logic, b2_logic]
    let updated = sgd_step(optimizer_logic, params)

    W1_logic = updated[0]
    b1_logic = updated[1]
    W2_logic = updated[2]
    b2_logic = updated[3]

    epoch = epoch + 1
}

print("âœ… Expert Logic trained\n\n")

// ============================================
// PHASE 3: TRAIN EXPERT General
// ============================================

print("â•â•â• PHASE 3: EXPERT GENERAL â•â•â•\n")
print("Task: Classification by range\n")
print("Dataset: 9 examples (3 categories)\n\n")

let X_general = tensor([
    10.0, 10.0,  // cat A
    11.0, 10.0,  // cat A
    10.0, 11.0,  // cat A
    12.0, 12.0,  // cat B
    13.0, 12.0,  // cat B
    12.0, 13.0,  // cat B
    14.0, 14.0,  // cat C
    15.0, 14.0,  // cat C
    14.0, 15.0   // cat C
], [9, 2])

let Y_general = tensor([
    1.0, 0.0, 0.0,  // A
    1.0, 0.0, 0.0,  // A
    1.0, 0.0, 0.0,  // A
    0.0, 1.0, 0.0,  // B
    0.0, 1.0, 0.0,  // B
    0.0, 1.0, 0.0,  // B
    0.0, 0.0, 1.0,  // C
    0.0, 0.0, 1.0,  // C
    0.0, 0.0, 1.0   // C
], [9, 3])

// Expert General: 2 â†’ 8 â†’ 3
let W1_general = tensor_randn_seeded([2, 8], 88)
W1_general = tensor_requires_grad(W1_general, true)
let b1_general = tensor_zeros([8])
b1_general = tensor_requires_grad(b1_general, true)

let W2_general = tensor_randn_seeded([8, 3], 99)
W2_general = tensor_requires_grad(W2_general, true)
let b2_general = tensor_zeros([3])
b2_general = tensor_requires_grad(b2_general, true)

print("Training Expert General (2000 epochs)...\n")

let optimizer_general = sgd_create(lr)
epoch = 0

while epoch < 2000 {
    let h1 = nn_linear(X_general, W1_general, b1_general)
    h1 = nn_relu(h1)
    let logits = nn_linear(h1, W2_general, b2_general)
    let loss = nn_cross_entropy_logits(logits, Y_general)

    tensor_backward(loss)

    let params = [W1_general, b1_general, W2_general, b2_general]
    let updated = sgd_step(optimizer_general, params)

    W1_general = updated[0]
    b1_general = updated[1]
    W2_general = updated[2]
    b2_general = updated[3]

    epoch = epoch + 1
}

print("âœ… Expert General trained\n\n")

// ============================================
// PHASE 4: TRAIN ROUTER
// ============================================

print("â•â•â• PHASE 4: ROUTER â•â•â•\n")
print("Task: Classify domain (Math/Logic/General)\n\n")

let X_router = tensor([
    // Math domain (0) - values 0-2
    0.0, 0.0,
    1.0, 0.0,
    0.0, 1.0,
    1.0, 1.0,
    2.0, 0.0,
    2.0, 1.0,
    1.0, 2.0,
    2.0, 2.0,
    0.0, 2.0,
    1.0, 1.0,

    // Logic domain (1) - values 3-5
    3.0, 4.0,
    4.0, 3.0,
    3.0, 3.0,
    5.0, 3.0,
    3.0, 5.0,
    4.0, 4.0,
    5.0, 4.0,
    4.0, 5.0,
    5.0, 5.0,
    3.0, 4.0,

    // General domain (2) - values 10-15
    10.0, 10.0,
    11.0, 10.0,
    10.0, 11.0,
    12.0, 12.0,
    13.0, 12.0,
    12.0, 13.0,
    14.0, 14.0,
    15.0, 14.0,
    14.0, 15.0,
    10.0, 10.0
], [30, 2])

let Y_router = tensor([
    // Math (domain 0)
    1.0, 0.0, 0.0,
    1.0, 0.0, 0.0,
    1.0, 0.0, 0.0,
    1.0, 0.0, 0.0,
    1.0, 0.0, 0.0,
    1.0, 0.0, 0.0,
    1.0, 0.0, 0.0,
    1.0, 0.0, 0.0,
    1.0, 0.0, 0.0,
    1.0, 0.0, 0.0,

    // Logic (domain 1)
    0.0, 1.0, 0.0,
    0.0, 1.0, 0.0,
    0.0, 1.0, 0.0,
    0.0, 1.0, 0.0,
    0.0, 1.0, 0.0,
    0.0, 1.0, 0.0,
    0.0, 1.0, 0.0,
    0.0, 1.0, 0.0,
    0.0, 1.0, 0.0,
    0.0, 1.0, 0.0,

    // General (domain 2)
    0.0, 0.0, 1.0,
    0.0, 0.0, 1.0,
    0.0, 0.0, 1.0,
    0.0, 0.0, 1.0,
    0.0, 0.0, 1.0,
    0.0, 0.0, 1.0,
    0.0, 0.0, 1.0,
    0.0, 0.0, 1.0,
    0.0, 0.0, 1.0,
    0.0, 0.0, 1.0
], [30, 3])

// Router: 2 â†’ 16 â†’ 3
let W1_router = tensor_randn_seeded([2, 16], 999)
W1_router = tensor_requires_grad(W1_router, true)
let b1_router = tensor_zeros([16])
b1_router = tensor_requires_grad(b1_router, true)

let W2_router = tensor_randn_seeded([16, 3], 777)
W2_router = tensor_requires_grad(W2_router, true)
let b2_router = tensor_zeros([3])
b2_router = tensor_requires_grad(b2_router, true)

print("Training Router (3000 epochs)...\n")

let optimizer_router = sgd_create(lr)
epoch = 0

while epoch < 3000 {
    let h1 = nn_linear(X_router, W1_router, b1_router)
    h1 = nn_relu(h1)
    let logits = nn_linear(h1, W2_router, b2_router)
    let loss = nn_cross_entropy_logits(logits, Y_router)

    tensor_backward(loss)

    let params = [W1_router, b1_router, W2_router, b2_router]
    let updated = sgd_step(optimizer_router, params)

    W1_router = updated[0]
    b1_router = updated[1]
    W2_router = updated[2]
    b2_router = updated[3]

    epoch = epoch + 1
}

print("âœ… Router trained\n\n")

// ============================================
// END-TO-END EVALUATION
// ============================================

print("â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—\n")
print("â•‘               COMPLETE SYSTEM EVALUATION                    â•‘\n")
print("â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n\n")

// Test 1: Math query â†’ Router â†’ Expert Math
print("TEST 1: Math Query (1 + 1 = ?)\n")
let test1 = tensor([1.0, 1.0], [1, 2])

let router_h1 = nn_linear(test1, W1_router, b1_router)
router_h1 = nn_relu(router_h1)
let router_logits = nn_linear(router_h1, W2_router, b2_router)
let domain1 = argmax(router_logits)

print("  Router â†’ Domain ")
print(domain1)

if domain1 == 0 {
    print(" (Math) âœ…\n")
    let math_h1 = nn_linear(test1, W1_math, b1_math)
    math_h1 = nn_relu(math_h1)
    let math_logits = nn_linear(math_h1, W2_math, b2_math)
    let result = argmax(math_logits)
    print("  Expert Math â†’ ")
    print(result)
    if result == 2 {
        print(" âœ… (expected: 2)\n\n")
    } else {
        print(" âŒ (expected: 2)\n\n")
    }
} else {
    print(" âŒ (expected: 0)\n\n")
}

// Test 2: Logic query â†’ Router â†’ Expert Logic
print("TEST 2: Logic Query (4 > 3 = ?)\n")
let test2 = tensor([4.0, 3.0], [1, 2])

router_h1 = nn_linear(test2, W1_router, b1_router)
router_h1 = nn_relu(router_h1)
router_logits = nn_linear(router_h1, W2_router, b2_router)
let domain2 = argmax(router_logits)

print("  Router â†’ Domain ")
print(domain2)

if domain2 == 1 {
    print(" (Logic) âœ…\n")
    let logic_h1 = nn_linear(test2, W1_logic, b1_logic)
    logic_h1 = nn_relu(logic_h1)
    let logic_logits = nn_linear(logic_h1, W2_logic, b2_logic)
    let result = argmax(logic_logits)
    print("  Expert Logic â†’ ")
    print(result)
    if result == 1 {
        print(" âœ… (4>3: yes)\n\n")
    } else {
        print(" âŒ (expected: 1)\n\n")
    }
} else {
    print(" âŒ (expected: 1)\n\n")
}

// Test 3: General query â†’ Router â†’ Expert General
print("TEST 3: General Query (category [13, 12])\n")
let test3 = tensor([13.0, 12.0], [1, 2])

router_h1 = nn_linear(test3, W1_router, b1_router)
router_h1 = nn_relu(router_h1)
router_logits = nn_linear(router_h1, W2_router, b2_router)
let domain3 = argmax(router_logits)

print("  Router â†’ Domain ")
print(domain3)

if domain3 == 2 {
    print(" (General) âœ…\n")
    let gen_h1 = nn_linear(test3, W1_general, b1_general)
    gen_h1 = nn_relu(gen_h1)
    let gen_logits = nn_linear(gen_h1, W2_general, b2_general)
    let result = argmax(gen_logits)
    print("  Expert General â†’ ")
    print(result)
    if result == 1 {
        print(" âœ… (category B)\n\n")
    } else {
        print(" âŒ (expected: 1)\n\n")
    }
} else {
    print(" âŒ (expected: 2)\n\n")
}

print("â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—\n")
print("â•‘              ğŸ¯ LEVEL 2 MoE COMPLETED âœ…                    â•‘\n")
print("â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n\n")

print("âœ¨ Architecture:\n")
print("   - Router: 2 â†’ 16 â†’ 3 (~80 params)\n")
print("   - Expert Math: 2 â†’ 16 â†’ 5 (~130 params)\n")
print("   - Expert Logic: 2 â†’ 8 â†’ 2 (~30 params)\n")
print("   - Expert General: 2 â†’ 8 â†’ 3 (~40 params)\n")
print("   - TOTAL: ~280 params\n\n")

print("âœ… Functional MoE system\n")
print("âœ… Router classifies domains\n")
print("âœ… Specialized experts execute tasks\n\n")

print("ğŸ“Š Next: LEVEL 3 - More experts and complex tasks\n")
